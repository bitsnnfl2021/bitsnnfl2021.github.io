---
layout: post
author:
  name: Paper ID 27
  difficulty: Easy
share: true
title: Show, Attend and Tell: Neural Image Caption Generation with Visual Attention
categories:
- image captioning
tags: []

---
**Abstract** - Inspired by recent work in machine translation
and object detection, we introduce an attention
based model that automatically learns to describe
the content of images. We describe how we
can train this model in a deterministic manner
using standard backpropagation techniques and
stochastically by maximizing a variational lower
bound. We also show through visualization how
the model is able to automatically learn to fix its
gaze on salient objects while generating the cor-
responding words in the output sequence. We
validate the use of attention with state-of-the-
art performance on three benchmark datasets:
Flickr8k, Flickr30k and MS COCO.

**Paper** - [https://arxiv.org/pdf/1502.03044.pdf](https://arxiv.org/pdf/1502.03044.pdf)

**Dataset -** [https://www.kaggle.com/adityajn105/flickr8k](https://www.kaggle.com/adityajn105/flickr8k)
    